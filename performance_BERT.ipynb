{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gensim import utils\n",
    "from markdown import markdown\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import KFold\n",
    "import gensim.parsing.preprocessing as gsp\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import (\n",
    "    make_scorer,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    ")\n",
    "import random\n",
    "import torch\n",
    "import transformers as ppb\n",
    "import warnings\n",
    "import scipy.sparse\n",
    "from scipy.sparse import hstack\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "source": [
    "Randomly picks data from the files. Used for testing purposes as full data can't be run on machine. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 0.35\n",
    "r = 0.1\n",
    "q = 0.001\n",
    "s = 0.001\n",
    "\n",
    "\n",
    "\n",
    "train_df = pd.read_csv(\"../data/filtered_typology_final.csv\", skiprows=lambda i: i>0 and random.random() > p)\n",
    "wow_unlabeled = pd.read_csv(\"../data/wow_uncoded_rules_codifying.csv\", skiprows=lambda i: i>0 and random.random() > r)\n",
    "minecraft_unlabeled = pd.read_csv(\"../data/minecraft_uncoded_rules_codifying.csv\", skiprows=lambda i: i>0 and random.random() > q)\n",
    "reddit_unlabeled = pd.read_csv(\"../data/reddit_uncoded_rules_codifying.csv\", skiprows=lambda i: i>0 and random.random() > s)\n",
    "\n",
    "unlabeled_list = [\"text\", \"communityID\", \"domain\"]\n",
    "wow_unlabeled, minecraft_unlabeled, reddit_unlabeled = (\n",
    "    wow_unlabeled[unlabeled_list],\n",
    "    minecraft_unlabeled[unlabeled_list],\n",
    "    reddit_unlabeled[unlabeled_list],\n",
    ")"
   ]
  },
  {
   "source": [
    "Picks out texts if the length of that text is less than 80, and places back into dataframe."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_df = train_df[train_df['text'].apply(lambda x: len(x) <= 80)]\n",
    "wow_unlabeled = wow_unlabeled[wow_unlabeled['text'].apply(lambda x: len(x) <= 80)]\n",
    "minecraft_unlabeled = minecraft_unlabeled[minecraft_unlabeled['text'].apply(lambda x: len(x) <= 80)]\n",
    "reddit_unlabeled = reddit_unlabeled[reddit_unlabeled['text'].apply(lambda x: len(x) <= 80)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Shape of training data:  (4349, 24)\nShape of wow_unlabeled:  (539, 3)\nShape of minecraft_unlabeled:  (296, 3)\nshape of reddit_unlabeled:  (547, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of training data: \", train_df.shape)\n",
    "print(\"Shape of wow_unlabeled: \", wow_unlabeled.shape)\n",
    "print(\"Shape of minecraft_unlabeled: \", minecraft_unlabeled.shape)\n",
    "print(\"shape of reddit_unlabeled: \", reddit_unlabeled.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing\n",
    "- remove useless characters, whitespace, stopwords  \n",
    "- lowercasing \n",
    "- stemming "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_html_markdown(s):\n",
    "    if type(s) not in [int, float] and s is not None:\n",
    "        return (\n",
    "            \" \".join(\n",
    "                re.split(\n",
    "                    \"[ _<>,.!|:#*\\n\\[\\]\\?]+\",\n",
    "                    \" \".join(\n",
    "                        BeautifulSoup(markdown(s), \"html.parser\").findAll(text=True)\n",
    "                    ),\n",
    "                )\n",
    "            )\n",
    "            .lower()\n",
    "            .strip()\n",
    "        )\n",
    "\n",
    "\n",
    "def whitespace_removal(df):\n",
    "    df.rule_norm_strategy = df.rule_norm_strategy.apply(lambda x: x.strip())\n",
    "    df.reg_const = df.reg_const.apply(lambda x: x.strip())\n",
    "    df.domain = df.domain.apply(lambda x: x.strip())\n",
    "    return df\n",
    "\n",
    "\n",
    "filters = [\n",
    "    gsp.strip_tags,\n",
    "    gsp.strip_punctuation,\n",
    "    gsp.strip_multiple_whitespaces,\n",
    "    gsp.strip_numeric,\n",
    "    gsp.remove_stopwords,\n",
    "    gsp.strip_short,\n",
    "    gsp.stem_text,\n",
    "]\n",
    "\n",
    "\n",
    "def clean_text(s):\n",
    "    if type(s) not in [int, float] and s is not None:\n",
    "        s = s.lower()\n",
    "        s = utils.to_unicode(s)\n",
    "        for f in filters:\n",
    "            s = f(s)\n",
    "        return s\n",
    "\n",
    "\n",
    "def randomShuffle(df):\n",
    "    return df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "def corpusGen(df):\n",
    "    return (\n",
    "        df.text.apply(strip_html_markdown)\n",
    "        .apply(lambda x: clean_text(x))\n",
    "        .astype(str)\n",
    "        .tolist()\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data transformation\n",
    "- generate corpus \n",
    "- transform the corpus to a normalized tf-idf representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corpusGen(df):\n",
    "    return (\n",
    "        df.text.apply(strip_html_markdown)\n",
    "        .apply(lambda x: clean_text(x))\n",
    "        .astype(str)\n",
    "        .tolist()\n",
    "    )\n",
    "\n",
    "\n",
    "train_df = randomShuffle(whitespace_removal(train_df))\n",
    "IS_corpus = corpusGen(train_df)\n",
    "wow_corpus = corpusGen(wow_unlabeled)\n",
    "minecraft_corpus = corpusGen(minecraft_unlabeled)\n",
    "reddit_corpus = corpusGen(reddit_unlabeled)\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 3), stop_words=None)\n",
    "X_IS = vectorizer.fit_transform(IS_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_precision_recall_f1(l, category, accuracy):\n",
    "    precision_recall_df = pd.DataFrame(\n",
    "        l, columns=[\"Precision\", \"Recall\", \"F1 Score\", \"Support\"]\n",
    "    )\n",
    "    precision_recall_df.drop(\"Support\", axis=1, inplace=True)\n",
    "    precision_recall_df.insert(0, \"Type\", category)\n",
    "    precision_recall_df.insert(1, \"Accuracy\", accuracy)\n",
    "    return precision_recall_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_class, tokenizer_class, pretrained_weights = (ppb.DistilBertModel, ppb.DistilBertTokenizer, 'distilbert-base-uncased')\n",
    "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "model = model_class.from_pretrained(pretrained_weights)"
   ]
  },
  {
   "source": [
    "Helper functions for BERT implmentation:\n",
    "- padded_token_Generator : tokenizes and pads values to the same length\n",
    "- BERT_feature_Gen : Generates BERT features and returns features\n",
    "- Tfidf_BERT_Combine : Combines tfidf features with bert features, returns sparse matrix."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def returnDataframe(l):\n",
    "    temp = pd.DataFrame(l)\n",
    "    temp = temp.rename(columns =  {0:'text'})\n",
    "    return temp\n",
    "\n",
    "def padded_token_Generator(df):\n",
    "    token = df['text'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))\n",
    "    max_len = 0\n",
    "    for i in token.values:\n",
    "        if len(i) > max_len:\n",
    "            max_len = len(i)\n",
    "            padded = np.array([i + [0]*(max_len-len(i)) for i in token.values])\n",
    "    return padded \n",
    "\n",
    "def BERT_feature_Gen(padded_tokens):\n",
    "    attention_mask = np.where(padded_tokens != 0, 1, 0)\n",
    "    input_ids = torch.tensor(np.array(padded_tokens)).long()\n",
    "    attention_mask = torch.tensor(attention_mask)\n",
    "    with torch.no_grad():\n",
    "        last_hidden_states = model(input_ids)\n",
    "    features = last_hidden_states[0][:,0,:].numpy()\n",
    "    return features\n",
    "\n",
    "def Tfidf_BERT_Combine(tfidf_features,bert_features):\n",
    "    features_Matrix = scipy.sparse.csr_matrix(bert_features)\n",
    "    combined = hstack([tfidf_features,features_Matrix])\n",
    "    return combined\n",
    "\n"
   ]
  },
  {
   "source": [
    "# BERT Implementaion"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_X_IS = returnDataframe(IS_corpus)\n",
    "temp_wow_corpus = returnDataframe(wow_corpus)\n",
    "temp_minecraft_corpus = returnDataframe(minecraft_corpus)\n",
    "temp_reddit_corpus = returnDataframe(reddit_corpus)"
   ]
  },
  {
   "source": [
    "Tokenizing Data for BERT feature generation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized = padded_token_Generator(temp_X_IS)\n",
    "tokenized_wow = padded_token_Generator(temp_wow_corpus)\n",
    "tokenized_mine = padded_token_Generator(temp_minecraft_corpus)\n",
    "tokenized_reddit = padded_token_Generator(temp_reddit_corpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_IS_BERT = BERT_feature_Gen(tokenized)\n",
    "X_IS_Combined = Tfidf_BERT_Combine(X_IS,X_IS_BERT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "BERT features shape:  (21, 768)\nTF-IDF features shape:  (21, 159)\nCombined features shape:  (21, 927)\n"
     ]
    }
   ],
   "source": [
    "print(\"BERT features shape: \", X_IS_BERT.shape)\n",
    "print(\"TF-IDF features shape: \", X_IS.shape)\n",
    "print(\"Combined features shape: \", X_IS_Combined.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_IS = []\n",
    "acc_IS = []\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "y_IS = train_df.IS.values.tolist()\n",
    "clf_IS = OneVsRestClassifier(LinearSVC())\n",
    "accuracy = cross_val_score(clf_IS, X_IS_Combined, y_IS, cv=kfold).mean()\n",
    "clf_IS.fit(X_IS_Combined, y_IS)\n",
    "y_IS_pred = cross_val_predict(clf_IS, X_IS_Combined, y_IS, cv=kfold)\n",
    "acc_IS.append(accuracy)\n",
    "l_IS.append(precision_recall_fscore_support(y_IS, y_IS_pred, average=\"weighted\"))\n",
    "IS_score = get_precision_recall_f1(l_IS, \"IS\", acc_IS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "wow_BERT = BERT_feature_Gen(tokenized_wow)\n",
    "mine_BERT = BERT_feature_Gen(tokenized_mine)\n",
    "reddit_BERT = BERT_feature_Gen(tokenized_reddit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "IS_X_wow, IS_X_minecraft, IS_X_reddit = (\n",
    "    vectorizer.transform(wow_corpus),\n",
    "    vectorizer.transform(minecraft_corpus),\n",
    "    vectorizer.transform(reddit_corpus),\n",
    ")\n",
    "\n",
    "WOW_X_IS = Tfidf_BERT_Combine(IS_X_wow,wow_BERT)\n",
    "Minecraft_X_IS = Tfidf_BERT_Combine(IS_X_minecraft,mine_BERT)\n",
    "Reddit_IS = Tfidf_BERT_Combine(IS_X_reddit,reddit_BERT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "BERT features shape:  (47, 768)\nTF-IDF features shape:  (47, 159)\nComined features shape:  (47, 927)\nBERT features shape:  (24, 768)\nTF-IDF features shape:  (24, 159)\nComined features shape:  (24, 927)\nBERT features shape:  (53, 768)\nTF-IDF features shape:  (53, 159)\nComined features shape:  (53, 927)\n"
     ]
    }
   ],
   "source": [
    "print(\"BERT features shape: \", wow_BERT.shape)\n",
    "print(\"TF-IDF features shape: \", IS_X_wow.shape)\n",
    "print(\"Comined features shape: \", WOW_X_IS.shape)\n",
    "\n",
    "print(\"BERT features shape: \", mine_BERT.shape)\n",
    "print(\"TF-IDF features shape: \", IS_X_minecraft.shape)\n",
    "print(\"Comined features shape: \", Minecraft_X_IS.shape)\n",
    "\n",
    "print(\"BERT features shape: \", reddit_BERT.shape)\n",
    "print(\"TF-IDF features shape: \", IS_X_reddit.shape)\n",
    "print(\"Comined features shape: \", Reddit_IS.shape)\n"
   ]
  },
  {
   "source": [
    "Predicting on wow, minecraft, and reddit data using BERT and TFIDF Features"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "wow_unlabeled[\"IS\"] = clf_IS.predict(WOW_X_IS)\n",
    "minecraft_unlabeled[\"IS\"] = clf_IS.predict(Minecraft_X_IS)\n",
    "reddit_unlabeled[\"IS\"] = clf_IS.predict(Reddit_IS)\n",
    "\n",
    "coded_df = train_df[unlabeled_list].copy()\n",
    "coded_df[\"IS\"] = clf_IS.predict(X_IS_Combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df[\n",
    "    (train_df[\"IS\"] == 1)\n",
    "    & (train_df[\"domain\"] == \"reddit\")\n",
    "    & (train_df[\"reg_const\"] != \"none\")\n",
    "]\n",
    "\n",
    "wow_unlabeled = wow_unlabeled[wow_unlabeled[\"IS\"] == 1]\n",
    "minecraft_unlabeled = minecraft_unlabeled[minecraft_unlabeled[\"IS\"] == 1]\n",
    "reddit_unlabeled = reddit_unlabeled[reddit_unlabeled[\"IS\"] == 1]\n",
    "coded_df = coded_df[coded_df[\"IS\"] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules_wow_corpus = corpusGen(wow_unlabeled)\n",
    "rules_minecraft_corpus = corpusGen(minecraft_unlabeled)\n",
    "rules_reddit_corpus = corpusGen(reddit_unlabeled)\n",
    "\n",
    "rules_corpus = corpusGen(train_df)\n",
    "rules_coded_corpus = corpusGen(coded_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rules = vectorizer.fit_transform(rules_corpus)\n",
    "X_coded = vectorizer.transform(rules_coded_corpus)\n",
    "X_wow = vectorizer.transform(rules_wow_corpus)\n",
    "X_minecraft = vectorizer.transform(rules_minecraft_corpus)\n",
    "X_reddit = vectorizer.transform(rules_reddit_corpus)\n"
   ]
  },
  {
   "source": [
    "Tokenizing rules to prep for BERT Feature generation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_X_rules = returnDataframe(rules_corpus)\n",
    "temp_X_coded = returnDataframe(rules_coded_corpus)\n",
    "temp_X_wow = returnDataframe(rules_wow_corpus)\n",
    "temp_X_minecraft = returnDataframe(rules_minecraft_corpus)\n",
    "temp_X_reddit = returnDataframe(rules_reddit_corpus)\n",
    "\n",
    "\n",
    "tokenized_X_rules = padded_token_Generator(temp_X_rules)\n",
    "tokenized_X_coded = padded_token_Generator(temp_X_coded)\n",
    "tokenized_X_wow = padded_token_Generator(temp_X_wow)\n",
    "tokenized_X_minecraft = padded_token_Generator(temp_X_minecraft)\n",
    "tokenized_X_reddit = padded_token_Generator(temp_X_reddit)\n"
   ]
  },
  {
   "source": [
    "Generating features for BERT and combining with TF-IDF"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_rules_BERT = BERT_feature_Gen(tokenized_X_rules)\n",
    "X_coded_BERT = BERT_feature_Gen(tokenized_X_coded)\n",
    "X_wow_BERT = BERT_feature_Gen(tokenized_X_wow)\n",
    "X_minecraft_BERT = BERT_feature_Gen(tokenized_X_minecraft)\n",
    "X_reddit_BERT = BERT_feature_Gen(tokenized_X_reddit)\n",
    "\n",
    "\n",
    "X_rules_Combined = Tfidf_BERT_Combine(X_rules,X_rules_BERT)\n",
    "X_coded_Combined = Tfidf_BERT_Combine(X_coded,X_coded_BERT)\n",
    "X_wow_Combined = Tfidf_BERT_Combine(X_wow,X_wow_BERT)\n",
    "X_minecraft_Combined = Tfidf_BERT_Combine(X_minecraft,X_minecraft_BERT)\n",
    "X_reddit_Combined = Tfidf_BERT_Combine(X_reddit,X_reddit_BERT)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                 Type  Accuracy  Precision    Recall  F1 Score\n",
       "0                  IS      0.75   0.721805  0.761905  0.741313\n",
       "0           reg_const      0.80   0.714286  0.714286  0.714286\n",
       "1  rule_norm_strategy      0.20   0.111111  0.142857  0.125000\n",
       "2       position_type      0.95   0.862245  0.928571  0.894180\n",
       "3       boundary_type      1.00   1.000000  1.000000  1.000000\n",
       "4    aggregation_type      0.90   0.862245  0.928571  0.894180\n",
       "5         payoff_type      1.00   1.000000  1.000000  1.000000\n",
       "6    information_type      0.90   0.857143  0.857143  0.857143\n",
       "7  communication_type      0.95   0.862245  0.928571  0.894180\n",
       "8         choice_type      0.50   0.375000  0.500000  0.428571\n",
       "9          scope_type      0.95   0.934524  0.928571  0.922981"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Type</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1 Score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>IS</td>\n      <td>0.75</td>\n      <td>0.721805</td>\n      <td>0.761905</td>\n      <td>0.741313</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>reg_const</td>\n      <td>0.80</td>\n      <td>0.714286</td>\n      <td>0.714286</td>\n      <td>0.714286</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>rule_norm_strategy</td>\n      <td>0.20</td>\n      <td>0.111111</td>\n      <td>0.142857</td>\n      <td>0.125000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>position_type</td>\n      <td>0.95</td>\n      <td>0.862245</td>\n      <td>0.928571</td>\n      <td>0.894180</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>boundary_type</td>\n      <td>1.00</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>aggregation_type</td>\n      <td>0.90</td>\n      <td>0.862245</td>\n      <td>0.928571</td>\n      <td>0.894180</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>payoff_type</td>\n      <td>1.00</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>information_type</td>\n      <td>0.90</td>\n      <td>0.857143</td>\n      <td>0.857143</td>\n      <td>0.857143</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>communication_type</td>\n      <td>0.95</td>\n      <td>0.862245</td>\n      <td>0.928571</td>\n      <td>0.894180</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>choice_type</td>\n      <td>0.50</td>\n      <td>0.375000</td>\n      <td>0.500000</td>\n      <td>0.428571</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>scope_type</td>\n      <td>0.95</td>\n      <td>0.934524</td>\n      <td>0.928571</td>\n      <td>0.922981</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 66
    }
   ],
   "source": [
    "l_rules = []\n",
    "acc_rules = []\n",
    "categories = [\n",
    "    \"reg_const\",\n",
    "    \"rule_norm_strategy\",\n",
    "    \"position_type\",\n",
    "    \"boundary_type\",\n",
    "    \"aggregation_type\",\n",
    "    \"payoff_type\",\n",
    "    \"information_type\",\n",
    "    \"communication_type\",\n",
    "    \"choice_type\",\n",
    "    \"scope_type\",\n",
    "]\n",
    "\n",
    "clf_rules = OneVsRestClassifier(LinearSVC())\n",
    "\n",
    "for c in categories:\n",
    "    y_rules = train_df[c].values.tolist()\n",
    "    accuracy_rules = cross_val_score(clf_rules, X_rules_Combined, y_rules, cv=kfold).mean()\n",
    "    y_rules_pred = cross_val_predict(clf_rules, X_rules_Combined, y_rules, cv=kfold)\n",
    "    acc_rules.append(accuracy_rules)\n",
    "    l_rules.append(\n",
    "        precision_recall_fscore_support(y_rules, y_rules_pred, average=\"weighted\")\n",
    "    )\n",
    "    clf_rules.fit(X_rules_Combined, y_rules)\n",
    "\n",
    "    wow_unlabeled[c] = clf_rules.predict(X_wow_Combined)\n",
    "    minecraft_unlabeled[c] = clf_rules.predict(X_minecraft_Combined)\n",
    "    reddit_unlabeled[c] = clf_rules.predict(X_reddit_Combined)\n",
    "    coded_df[c] = clf_rules.predict(X_coded_Combined)\n",
    "\n",
    "rules_scores = get_precision_recall_f1(l_rules, categories, acc_rules)\n",
    "pd.concat([IS_score, rules_scores])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../output/wow_labeled.csv'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-67-ae2e54bff500>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mwow_unlabeled\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"../output/wow_labeled.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mminecraft_unlabeled\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"../output/minecraft_labeled.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mreddit_unlabeled\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"../output/reddit_labeled.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mcoded_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"../output/coded_labeled.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3382\u001b[0m         )\n\u001b[0;32m   3383\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3384\u001b[1;33m         return DataFrameRenderer(formatter).to_csv(\n\u001b[0m\u001b[0;32m   3385\u001b[0m             \u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3386\u001b[0m             \u001b[0mline_terminator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mline_terminator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\formats\\format.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m   1081\u001b[0m             \u001b[0mformatter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfmt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1082\u001b[0m         )\n\u001b[1;32m-> 1083\u001b[1;33m         \u001b[0mcsv_formatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1084\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1085\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcreated_buffer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    226\u001b[0m         \"\"\"\n\u001b[0;32m    227\u001b[0m         \u001b[1;31m# apply compression and byte/text conversion\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 228\u001b[1;33m         with get_handle(\n\u001b[0m\u001b[0;32m    229\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    637\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    638\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 639\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    640\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../output/wow_labeled.csv'"
     ]
    }
   ],
   "source": [
    "wow_unlabeled.to_csv(\"../output/wow_labeled.csv\", index=False)\n",
    "minecraft_unlabeled.to_csv(\"../output/minecraft_labeled.csv\", index=False)\n",
    "reddit_unlabeled.to_csv(\"../output/reddit_labeled.csv\", index=False)\n",
    "coded_df.to_csv(\"../output/coded_labeled.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}